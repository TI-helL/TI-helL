# Ensemble 방법들

#### Voting
* Hard voting: 다수결로 결정
* Soft voting; 가중치의 합으로 결정

#### Bagging(Bootstrap Aggregating)
* Bootstrap : 기존 데이터셋에서 여러번 sampling하여 여러 개의 
데이터셋을 생성한 후, 각각 학습
* 예시: [Random Forest](https://tyami.github.io/machine%20learning/ensemble-2-bagging-random-forest/)

#### Boosting
1. [Adaboost](https://tyami.github.io/machine%20learning/ensemble-3-boosting-AdaBoost/)
2. Gradient Boosting
3. XGBoost
4. LightGBM
5. CatBoost
6. NGBoost

#### Stacking
*

[참고](https://tyami.github.io/machine%20learning/ensemble-1-basics/)