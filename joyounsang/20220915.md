빅데이터 처리
-Hadoop Eco-system 기반의 Batch(배치)처리 아키텍처 일반
    Log Collector : 로그 이벤트 수집기 Layer로 가장 많이 사용되는 것은 Apache Flume
    DB Collector : DB에 저장된 데이터를 간편하기 수집하기 위한 Apache Sqoop (Sql-to-Hadoop)
    Data Store : 분산 파일 시스템인 Apache Hadoop - HDFS
    Data Analysis : 데이터 분석을 위한 Apache Pig, Hive, Map/Reduce. 이 세가지는 M/R기반이라 속도가 느리다.
        따라서, 좀 더 빠른 분석을 원한다면 Facebook Presto, Apache Spark 그리고, 국산 그루터 Tajo 등이 있다
        Hive와 Preso 간략 비교하자면, 간단한 count의 경우 20배이상, 복잡 query의 경우도 5-10배 정도로 Presto가 빠르다
    Workflow : Job 제어를 위한 Workflow는 Apache Oozie, LinkedIn의 Azkaban 등이 있다.

-CEP 아키텍처 기반의 Real-time(실시간)처리 아키텍처 일반
    Log Collector : 이벤트를 실시간으로 수집하기 위해 Thrift 등 TCP기반으로 수집하기 위해 Apache Flume이 적당하다.
    Message Queue : 이벤트를 임시로 저장하기 위해 Apache Kafka를 사용한다.
    Real-time Pre-Processing : 실시간으로 전처리가 필요할 경우, Real-time Hadoop이라 불리는
    Twitter에서 만든 Apache Storm이 매우 효과적이다.
    Real-time Computing : 실시간 계산 및 실시간 패턴 분석을 위해 대표적인 CEP 엔진인 Esper가 많이 사용된다.
    상용의 솔루션도 사용하고 있는 제품이다.